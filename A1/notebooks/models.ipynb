{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE CNN\n",
    "- 思路：先做Jupyterbooks，有了运行结果后放进class跑。11号今天写CNN并跑出基本结果。\n",
    "- train (5509260, 14) , validation (1836420, 14) , test (1836420, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../src/train.csv'\n",
    "valid_path = '../src/validation.csv'\n",
    "test_path = '../src/test.csv'\n",
    "combined_path = '../src/combined_file.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    # column_names = ['subject','activity','time_s', 'lw_x','lw_y','lw_z','lh_x','lh_y','lh_z','la_x','la_y','la_z','ra_x','ra_y','ra_z']\n",
    "    columns_to_drop = ['lw_x', 'lw_y', 'lw_z', 'lh_x', 'lh_y', 'lh_z', 'la_x', 'la_y', 'la_z', 'ra_x', 'ra_y', 'ra_z']\n",
    "    data = pd.read_csv(file_path,header = 0)\n",
    "    # Drop the columns from the DataFrame\n",
    "    df = data.drop(columns=columns_to_drop)\n",
    "    return df\n",
    "\n",
    "def plot_axis(ax, x, y, title):\n",
    "    ax.plot(x, y)\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\n",
    "    ax.set_xlim([min(x), max(x)])\n",
    "    ax.grid(True)\n",
    "    \n",
    "def plot_activity(activity,data):\n",
    "    fig, (ax0, ax1, ax2, ax3) = plt.subplots(nrows = 4, figsize = (15, 10), sharex = True)\n",
    "    plot_axis(ax0, data['time_s'], data['magnitude_lw'], 'magnitude_lw')\n",
    "    plot_axis(ax1, data['time_s'], data['magnitude_lh'], 'magnitude_lh')\n",
    "    plot_axis(ax2, data['time_s'], data['magnitude_la'], 'magnitude_la')\n",
    "    plot_axis(ax3, data['time_s'], data['magnitude_ra'], 'magnitude_ra')\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    fig.suptitle(activity)\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reference_df = read_data(train_path)\n",
    "train_df = train_reference_df.copy()\n",
    "train_df = train_df\n",
    "val_reference_df = read_data(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable smoke test\n",
    "smoke_test = True\n",
    "smoke_test_size = 50\n",
    "\n",
    "\n",
    "if smoke_test:\n",
    "    train_reference_df = train_reference_df[:smoke_test_size]\n",
    "\n",
    "    val_reference_df = val_reference_df[:smoke_test_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (50, 6) , Y_train shape is (50,)\n"
     ]
    }
   ],
   "source": [
    "train_reference_df.shape\n",
    "column_names = ['subject','activity']\n",
    "Y_train = train_reference_df['activity']\n",
    "X_train = train_reference_df.drop(columns=column_names)\n",
    "\n",
    "print(f'X_train shape is {X_train.shape} , Y_train shape is {Y_train.shape}')\n",
    "# x_train = train_reference_df[column_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = Y_train - np.min(Y_train)  # Ensure labels start from 0\n",
    "num_classes = len(np.unique(Y_train))\n",
    "\n",
    "Y_train = to_categorical(Y_train, num_classes=num_classes)\n",
    "\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (50, 6) , Y_train shape is (50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape is {X_train.shape} , Y_train shape is {Y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/menglutao/.pyenv/versions/3.8.10/envs/HDA/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a55711f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(6,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # replace num_classes with the number of classes\n",
    "\n",
    "\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Convert your dataframe to numpy arrays for training\n",
    "# X_train = X_train.values\n",
    "# Y_train = Y_train.values\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
