{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab48d291-3ded-445f-9b7b-07fc7103ccb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data.data_segmentation import DataSegmentation\n",
    "from data.data_loader import DataLoader\n",
    "from models.LSTM_model import LSTM_Network,Config\n",
    "from models.CNN_model import read_data,make_input_data,CNNModel\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from utils.activity_type import ActivityType\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "tf.random.set_seed(1234)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f57903-fc04-4131-8479-1a2074869733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Output classes to learn how to classify\n",
    "LABELS = [\n",
    "    \"Walking\",\n",
    "    \"Descending Stairs\",\n",
    "    \"Ascending Stairs\"\n",
    "]\n",
    "\n",
    "data_loader = DataLoader(\"dataset/labeled-raw-accelerometry-data-captured-during-walking-stair-climbing-and-driving-1.0.0/raw_accelerometry_data\")\n",
    "data_loader.download_data()\n",
    "data_loader.read_files()\n",
    "\n",
    "data_seg = DataSegmentation(window_duration=2.56, overlap=0.5, sampling_rate=50)\n",
    "train_data_X,train_data_y = data_seg(data_loader.train_data)\n",
    "test_data_X,test_data_y = data_seg(data_loader.test_data)\n",
    "\n",
    "label_mapping = ActivityType.create_label_mapping()\n",
    "print(\"label_mapping:\",label_mapping)\n",
    "one_hot_encoded_train_y = ActivityType.one_hot(train_data_y, label_mapping)\n",
    "one_hot_encoded_test_y = ActivityType.one_hot(test_data_y, label_mapping)\n",
    "final_train_y = one_hot_encoded_train_y.reshape(one_hot_encoded_train_y.shape[0],-1)\n",
    "final_test_y = one_hot_encoded_test_y.reshape(one_hot_encoded_test_y.shape[0],-1)\n",
    "\n",
    "config = Config(train_data_X, test_data_X)\n",
    "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "print(\"features shape, labels shape, each features mean, each features standard deviation\")\n",
    "print(test_data_X.shape, final_test_y.shape,\n",
    "      np.mean(test_data_X), np.std(test_data_X))\n",
    "print(\"the dataset is therefore properly normalised, as expected.\")\n",
    "print(train_data_X.shape, final_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430731fc-27ec-49e6-b68e-3b58bd60e27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_counts = dict(zip(LABELS, np.sum(final_train_y, axis=0)))\n",
    "\n",
    "# Print the counts for each class\n",
    "print(\"Class Counts:\")\n",
    "for label, count in class_counts.items():\n",
    "    print(f\"{label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f36caf-e1f2-41bb-9448-6de77d7aac01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(\"Number of training samples:\", len(train_data_X))\n",
    "print(\"Number of testing samples:\", len(test_data_X))\n",
    "print(\"Number of features per sample:\", train_data_X.shape[1])\n",
    "print(\"Number of classes:\", len(LABELS))\n",
    "\n",
    "# Plot four subplots, each containing three features\n",
    "num_subplots = 4\n",
    "features_per_subplot = 3\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "example_index = 0\n",
    "\n",
    "for i in range(num_subplots):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    \n",
    "\n",
    "    for axis in range(features_per_subplot):\n",
    "        plt.plot(train_data_X[example_index, :, i*3+axis], label=f'Axis {axis + 1}')\n",
    "\n",
    "    plt.title(f\"Example Data - {LABELS[np.argmax(final_train_y[example_index])]}\")\n",
    "    plt.xlabel(\"Time Steps\")\n",
    "    plt.ylabel(\"Acceleration\")\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f17e3-0e96-442d-abcd-e1807e2027a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to find an example from each class\n",
    "def find_example_from_each_class(data, labels):\n",
    "    unique_labels = np.unique(labels, axis=0)\n",
    "    examples = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        index = np.argmax(np.all(labels == label, axis=1))\n",
    "        examples.append((data[index], label))\n",
    "\n",
    "    return examples\n",
    "\n",
    "# Find an example from each class\n",
    "examples = find_example_from_each_class(train_data_X, final_train_y)\n",
    "\n",
    "# Plot four subplots, each containing three features\n",
    "num_subplots = 3\n",
    "features_per_subplot = 3\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(num_subplots):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    example_data, example_label = examples[i]\n",
    "\n",
    "    for axis in range(features_per_subplot):\n",
    "        plt.plot(example_data[:, axis], label=f'Axis {axis + 1}')\n",
    "\n",
    "    plt.title(f\"Example Data - {LABELS[np.argmax(example_label)]}\")\n",
    "    plt.xlabel(\"Time Steps\")\n",
    "    plt.ylabel(\"Acceleration\")\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d650d-836f-442c-8e14-a02fb6e11997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to find an example from each class\n",
    "def find_example_from_each_class(data, labels):\n",
    "    unique_labels = np.unique(labels, axis=0)\n",
    "    examples = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        index = np.argmax(np.all(labels == label, axis=1))\n",
    "        examples.append((data[index], label))\n",
    "\n",
    "    return examples\n",
    "\n",
    "# Find an example from each class\n",
    "examples = find_example_from_each_class(train_data_X, final_train_y)\n",
    "\n",
    "# Plot four figures, each containing three subplots for each class\n",
    "num_figures = 4\n",
    "num_subplots_per_figure = 3\n",
    "features_per_subplot = 3\n",
    "\n",
    "all_features = range(train_data_X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb268f-2f58-4190-b4ef-95ef72e83c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subplot_index = 3\n",
    "range(features_per_subplot+(subplot_index-1)*3,features_per_subplot+subplot_index*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c9461-23cb-491c-b8ca-25b20754cf17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for figure_index in range(num_figures):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for subplot_index in range(num_subplots_per_figure):\n",
    "        plt.subplot(2, 2, subplot_index + 1)\n",
    "        \n",
    "        for feature_index in range(features_per_subplot+(figure_index-1)*3,features_per_subplot+figure_index*3) :\n",
    "            example_data, example_label = examples[subplot_index]\n",
    "            plt.plot(example_data[:, feature_index], label=f'Feature {all_features[feature_index] + 1}')\n",
    "\n",
    "        plt.title(f\"Class: {LABELS[np.argmax(example_label)]}\")\n",
    "        plt.xlabel(\"Time Steps\")\n",
    "        plt.ylabel(\"Acceleration\")\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01fc37-0789-4062-8532-4b3f8b7d2966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Step 3: Let's get serious and build the neural network\n",
    "# ------------------------------------------------------\n",
    "\n",
    "X = tf.compat.v1.placeholder(tf.float32, [None, config.n_steps, config.n_inputs])\n",
    "Y = tf.compat.v1.placeholder(tf.float32, [None, config.n_classes])\n",
    "\n",
    "pred_Y = LSTM_Network(X, config)\n",
    "\n",
    "# # Loss,optimizer,evaluation\n",
    "l2 = config.lambda_loss_amount * \\\n",
    "    sum(tf.nn.l2_loss(tf_var) for tf_var in tf.compat.v1.trainable_variables())\n",
    "# Softmax loss and L2\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf.stop_gradient(Y), logits=pred_Y)) + l2\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(\n",
    "    learning_rate=config.learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred_Y, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb2cf59-a46a-4a37-a56f-5b197241a7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Step 4: Hooray, now train the neural network\n",
    "# --------------------------------------------\n",
    "\n",
    "# Note that log_device_placement can be turned ON but will cause console spam with RNNs.\n",
    "sess = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(log_device_placement=False))\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "best_accuracy = 0.0\n",
    "# Start training for each batch and loop epochs\n",
    "for i in range(config.training_epochs):\n",
    "    for start, end in zip(range(0, config.train_count, config.batch_size),\n",
    "                          range(config.batch_size, config.train_count + 1, config.batch_size)):\n",
    "        sess.run(optimizer, feed_dict={X: train_data_X[start:end],\n",
    "                                       Y: final_train_y[start:end]})\n",
    "\n",
    "    # Test completely at every epoch: calculate accuracy\n",
    "    pred_out, accuracy_out, loss_out = sess.run(\n",
    "        [pred_Y, accuracy, cost],\n",
    "        feed_dict={\n",
    "            X: test_data_X,\n",
    "            Y: final_test_y\n",
    "        }\n",
    "    )\n",
    "    print(\"traing iter: {},\".format(i) +\n",
    "          \" test accuracy : {},\".format(accuracy_out) +\n",
    "          \" loss : {}\".format(loss_out))\n",
    "    best_accuracy = max(best_accuracy, accuracy_out)\n",
    "\n",
    "print(\"\")\n",
    "print(\"final test accuracy: {}\".format(accuracy_out))\n",
    "print(\"best epoch's test accuracy: {}\".format(best_accuracy))\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e386172c-f363-4146-a0e4-a12b3cf05d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(128, 12)))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(128, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(3, activation='softmax'))  # Assuming 3 classes\n",
    "\n",
    "#optimizer = tfa.optimizers.AdamW(weight_decay=1e-4)\n",
    "# Compile the model\n",
    "model.compile(optimizer= 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data_X, final_train_y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_data_X, final_test_y)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb546fe-6632-437f-be02-a0ffc8a47d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_addons as tfa\n",
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(128, 12)))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(128, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(3, activation='softmax'))  # Assuming 3 classes\n",
    "\n",
    "#optimizer = tfa.optimizers.AdamW(weight_decay=1e-4)\n",
    "# Compile the model\n",
    "model.compile(optimizer= 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data_X, final_train_y, epochs=10, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_data_X, final_test_y)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821518b0-0b3d-477c-b2ca-f239e57bfc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(128, 12)))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(128, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(3, activation='softmax'))  # Assuming 3 classes\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_funct = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# Compile the model\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-7)\n",
    "model.compile(optimizer = adam_optimizer, loss = loss_funct, metrics = [\"accuracy\"]) #(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data_X, final_train_y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_data_X, final_test_y)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5af3a7-2b4f-4763-a3f0-87daa5caeea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming your model is already trained (e.g., 'model' is your trained model)\n",
    "\n",
    "# Predict class probabilities for the test set\n",
    "predicted_probs = model.predict(test_data_X)\n",
    "\n",
    "# Extract predicted class labels\n",
    "predicted_labels = np.argmax(predicted_probs, axis=1)\n",
    "\n",
    "# Convert one-hot encoded true labels to class indices\n",
    "true_labels = np.argmax(final_test_y, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Create a heatmap of the confusion matrix using matplotlib\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "classes = ['Walking', 'Descending Stairs', 'Ascending Stairs']\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Display the values inside the heatmap\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, str(conf_matrix[i, j]), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd85cd-fc20-481f-8471-85bb91d08465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional layers with dropout and max pooling\n",
    "model.add(layers.Conv1D(16, kernel_size=3, activation='relu', input_shape=(128, 12)))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Conv1D(32, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Conv1D(128, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Conv1D(256, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(3, activation='softmax'))  # Assuming 3 classes\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
    "loss_funct = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, decay=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model and plot accuracy through epochs\n",
    "history = model.fit(train_data_X, final_train_y, epochs=25, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy Through Epochs')\n",
    "plt.show()\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_data_X, final_test_y)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Assuming your model is already trained (e.g., 'model' is your trained model)\n",
    "\n",
    "# Predict class probabilities for the test set\n",
    "predicted_probs = model.predict(test_data_X)\n",
    "\n",
    "# Extract predicted class labels\n",
    "predicted_labels = np.argmax(predicted_probs, axis=1)\n",
    "\n",
    "# Convert one-hot encoded true labels to class indices\n",
    "true_labels = np.argmax(final_test_y, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Create a heatmap of the confusion matrix using matplotlib\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "classes = ['Walking', 'Descending Stairs', 'Ascending Stairs']\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Display the values inside the heatmap\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, str(conf_matrix[i, j]), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c544f-10ee-4dab-939a-7b62b397101e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
